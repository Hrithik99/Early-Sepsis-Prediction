{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_data_validation as tfdv\n",
    "#from tensorflow_data_validation.utils import display_util\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from dags.utils.logger_config import setup_logging\n",
    "logger = setup_logging('.',\"x.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:02:08,758 - x.py - INFO - yy\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"yy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 'int64',\n",
       " 'Hour': 'int64',\n",
       " 'HR': 'float64',\n",
       " 'O2Sat': 'float64',\n",
       " 'Temp': 'float64',\n",
       " 'SBP': 'float64',\n",
       " 'MAP': 'float64',\n",
       " 'DBP': 'float64',\n",
       " 'Resp': 'float64',\n",
       " 'EtCO2': 'float64',\n",
       " 'BaseExcess': 'float64',\n",
       " 'HCO3': 'float64',\n",
       " 'FiO2': 'float64',\n",
       " 'pH': 'float64',\n",
       " 'PaCO2': 'float64',\n",
       " 'SaO2': 'float64',\n",
       " 'AST': 'float64',\n",
       " 'BUN': 'float64',\n",
       " 'Alkalinephos': 'float64',\n",
       " 'Calcium': 'float64',\n",
       " 'Chloride': 'float64',\n",
       " 'Creatinine': 'float64',\n",
       " 'Bilirubin_direct': 'float64',\n",
       " 'Glucose': 'float64',\n",
       " 'Lactate': 'float64',\n",
       " 'Magnesium': 'float64',\n",
       " 'Phosphate': 'float64',\n",
       " 'Potassium': 'float64',\n",
       " 'Bilirubin_total': 'float64',\n",
       " 'TroponinI': 'float64',\n",
       " 'Hct': 'float64',\n",
       " 'Hgb': 'float64',\n",
       " 'PTT': 'float64',\n",
       " 'WBC': 'float64',\n",
       " 'Fibrinogen': 'float64',\n",
       " 'Platelets': 'float64',\n",
       " 'Age': 'float64',\n",
       " 'Gender': 'int64',\n",
       " 'Unit1': 'float64',\n",
       " 'Unit2': 'float64',\n",
       " 'HospAdmTime': 'float64',\n",
       " 'ICULOS': 'int64',\n",
       " 'SepsisLabel': 'int64',\n",
       " 'Patient_ID': 'int64'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {col: str(df[col].dtype) for col in df.columns}\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patient_ids = df['Patient_ID'].drop_duplicates().head(24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Patient_ID'].isin(unique_patient_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_patient_ids=filtered_df['Patient_ID'].drop_duplicates().head(18000)\n",
    "test_unique_patient_ids=filtered_df['Patient_ID'].drop_duplicates().tail(6000)\n",
    "train_df = df[df['Patient_ID'].isin(train_unique_patient_ids)]\n",
    "test_df=df[df['Patient_ID'].isin(test_unique_patient_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dags.utils.logger_config import setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from dags.utils.logger_config import setup_logging\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "logger=logging.getLogger('Data_Validation.py')\n",
    "\n",
    "STATS_SCHEMA_FILE = 'schema_and_stats.json'\n",
    "\n",
    "def convert_to_serializable(value):\n",
    "    \"\"\"\n",
    "    Convert a value to a JSON-serializable format.\n",
    "\n",
    "    Args:\n",
    "        value: The value to convert.\n",
    "\n",
    "    Returns:\n",
    "        The converted value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, (np.integer, np.floating)):\n",
    "        return value.item()\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value.tolist()\n",
    "    return value\n",
    "\n",
    "def generate_and_save_schema_and_stats(df, schema_file=STATS_SCHEMA_FILE):\n",
    "    \"\"\"\n",
    "    Generate the schema and statistics from a DataFrame and save them to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame from which to infer the schema and statistics.\n",
    "        schema_file (str): Path to save the schema and statistics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema = {\n",
    "        \"HR\": \"float64\",\n",
    "        \"O2Sat\": \"float64\",\n",
    "        \"Temp\": \"float64\",\n",
    "        \"SBP\": \"float64\",\n",
    "        \"MAP\": \"float64\",\n",
    "        \"DBP\": \"float64\",\n",
    "        \"Resp\": \"float64\",\n",
    "        \"EtCO2\": \"float64\",\n",
    "        \"BaseExcess\": \"float64\",\n",
    "        \"HCO3\": \"float64\",\n",
    "        \"FiO2\": \"float64\",\n",
    "        \"pH\": \"float64\",\n",
    "        \"PaCO2\": \"float64\",\n",
    "        \"SaO2\": \"float64\",\n",
    "        \"AST\": \"float64\",\n",
    "        \"BUN\": \"float64\",\n",
    "        \"Alkalinephos\": \"float64\",\n",
    "        \"Calcium\": \"float64\",\n",
    "        \"Chloride\": \"float64\",\n",
    "        \"Creatinine\": \"float64\",\n",
    "        \"Bilirubin_direct\": \"float64\",\n",
    "        \"Glucose\": \"float64\",\n",
    "        \"Lactate\": \"float64\",\n",
    "        \"Magnesium\": \"float64\",\n",
    "        \"Phosphate\": \"float64\",\n",
    "        \"Potassium\": \"float64\",\n",
    "        \"Bilirubin_total\": \"float64\",\n",
    "        \"TroponinI\": \"float64\",\n",
    "        \"Hct\": \"float64\",\n",
    "        \"Hgb\": \"float64\",\n",
    "        \"PTT\": \"float64\",\n",
    "        \"WBC\": \"float64\",\n",
    "        \"Fibrinogen\": \"float64\",\n",
    "        \"Platelets\": \"float64\",\n",
    "        \"Age\": \"float64\",\n",
    "        \"Gender\": \"int64\",\n",
    "        \"Unit1\": \"float64\",\n",
    "        \"Unit2\": \"float64\",\n",
    "        \"HospAdmTime\": \"float64\",\n",
    "        \"ICULOS\": \"int64\",\n",
    "        \"SepsisLabel\": \"int64\",\n",
    "        \"Patient_ID\": \"int64\"  # Assuming Patient_ID is extracted as a string\n",
    "        }\n",
    "        stats = {}\n",
    "        for col in df.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                stats[col] = {\n",
    "                    'min': convert_to_serializable(df[col].min()),\n",
    "                    'max': convert_to_serializable(df[col].max()),\n",
    "                    'mean': convert_to_serializable(df[col].mean()) if not df[col].isnull().all() else None,\n",
    "                    'median': convert_to_serializable(df[col].median()) if not df[col].isnull().all() else None,\n",
    "                    'std': convert_to_serializable(df[col].std()) if not df[col].isnull().all() else None,\n",
    "                    'null_count': convert_to_serializable(df[col].isnull().sum())\n",
    "                }\n",
    "            else:\n",
    "                stats[col] = {\n",
    "                    'unique_values': convert_to_serializable(df[col].unique()),\n",
    "                    'null_count': convert_to_serializable(df[col].isnull().sum())\n",
    "                }\n",
    "        schema_and_stats = {'schema': schema, 'statistics': stats}\n",
    "        with open(schema_file, 'w') as f:\n",
    "            json.dump(schema_and_stats, f, indent=4)\n",
    "        logger.info(f\"Schema and statistics generated and saved to {schema_file}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating or saving schema and statistics: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_schema_and_stats(schema_file=STATS_SCHEMA_FILE):\n",
    "    \"\"\"\n",
    "    Load the schema and statistics from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        schema_file (str): Path to the schema and statistics file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Loaded schema and statistics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(schema_file, 'r') as f:\n",
    "            schema_and_stats = json.load(f)\n",
    "        logger.info(f\"Schema and statistics loaded from {schema_file}.\")\n",
    "        return schema_and_stats\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading schema and statistics from {schema_file}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_schema(df, schema):\n",
    "    \"\"\"\n",
    "    Validate the schema of the DataFrame against the expected schema.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to validate.\n",
    "        schema (dict): Expected schema.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if schema is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    for column, dtype in schema.items():\n",
    "        if column not in df.columns:\n",
    "            logger.error(f\"Missing column: {column}\")\n",
    "            return False\n",
    "        if str(df[column].dtype) != dtype:\n",
    "            logger.error(f\"Invalid type for column {column}. Expected {dtype}, got {df[column].dtype}\")\n",
    "            return False\n",
    "    logger.info(\"Schema validation passed.\")\n",
    "    return True\n",
    "\n",
    "def validate_statistics(df, stats):\n",
    "    \"\"\"\n",
    "    Validate statistics of the DataFrame against expected statistics.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to validate.\n",
    "        stats (dict): Expected statistics.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if statistics are valid, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for col, stat in stats.items():\n",
    "            if col not in df.columns:\n",
    "                logger.error(f\"Missing column: {col}\")\n",
    "                return False\n",
    "            \n",
    "            if col == 'Patient_ID':\n",
    "                if df[col].isnull().any():\n",
    "                    logger.error(\"The 'patient_id' column cannot have null values.\")\n",
    "                    return False\n",
    "                continue\n",
    "\n",
    "            if 'min' in stat and 'max' in stat:\n",
    "                if stat['min'] is not None and stat['max'] is not None:\n",
    "                    if df[col].min() < stat['min']:\n",
    "                        logger.warning(f\"Column {col} min value anomaly: {df[col].min()} < {stat['min']}\")\n",
    "                    if df[col].max() > stat['max']:\n",
    "                        logger.warning(f\"Column {col} max value anomaly: {df[col].max()} > {stat['max']}\")\n",
    "\n",
    "            if 'mean' in stat and 'std' in stat:\n",
    "                if stat['mean'] is not None and stat['std'] is not None:\n",
    "                    if not df[col].isnull().all():  # Check if any non-null values exist\n",
    "                        if abs(df[col].mean() - stat['mean']) > 3 * stat['std']:\n",
    "                            logger.warning(f\"Column {col} mean value anomaly: {df[col].mean()} != {stat['mean']}\")\n",
    "\n",
    "            if 'median' in stat and 'std' in stat:\n",
    "                if stat['median'] is not None and stat['std'] is not None:\n",
    "                    if not df[col].isnull().all():  # Check if any non-null values exist\n",
    "                        if abs(df[col].median() - stat['median']) > 3 * stat['std']:\n",
    "                            logger.warning(f\"Column {col} median value anomaly: {df[col].median()} != {stat['median']}\")\n",
    "\n",
    "            if 'null_count' in stat:\n",
    "                null_count = df[col].isnull().sum()\n",
    "                if stat['null_count'] is not None:\n",
    "                    if null_count > stat['null_count']:\n",
    "                        logger.warning(f\"Column {col} null value count anomaly: {null_count} > {stat['null_count']}\")\n",
    "\n",
    "            if 'unique_values' in stat:\n",
    "                if stat['unique_values'] is not None:\n",
    "                    unique_values = df[col].unique()\n",
    "                    if set(unique_values) != set(stat['unique_values']):\n",
    "                        logger.warning(f\"Column {col} unique values anomaly: {unique_values} != {stat['unique_values']}\")\n",
    "\n",
    "        logger.info(\"Statistical validation passed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during statistical validation: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"\n",
    "    Validate data against stored schema and statistics.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the data file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if validation passes, False if validation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        #df = pd.read_csv(file_path)\n",
    "        logger.info(f\"Data loaded successfully.\")\n",
    "\n",
    "        # Load schema and statistics\n",
    "        schema_and_stats = load_schema_and_stats()\n",
    "        schema = schema_and_stats['schema']\n",
    "        stats = schema_and_stats['statistics']\n",
    "\n",
    "        # Validate schema\n",
    "        if not validate_schema(df, schema):\n",
    "            logger.error(\"Schema validation failed.\")\n",
    "            return False\n",
    "\n",
    "        # Validate statistics\n",
    "        if not validate_statistics(df, stats):\n",
    "            logger.error(\"Statistical validation failed.\")\n",
    "            return False\n",
    "\n",
    "        logger.info(\"Data validation passed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during data validation: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 18:11:17,932 - Data_Validation.py - INFO - Schema and statistics generated and saved to schema_and_stats.json.\n"
     ]
    }
   ],
   "source": [
    "generate_and_save_schema_and_stats(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 18:11:38,040 - Data_Validation.py - INFO - Data loaded successfully.\n",
      "2024-06-06 18:11:38,040 - Data_Validation.py - INFO - Schema and statistics loaded from schema_and_stats.json.\n",
      "2024-06-06 18:11:38,041 - Data_Validation.py - INFO - Schema validation passed.\n",
      "2024-06-06 18:11:38,081 - Data_Validation.py - WARNING - Column Temp max value anomaly: 50.0 > 42.22\n",
      "2024-06-06 18:11:38,093 - Data_Validation.py - WARNING - Column SBP min value anomaly: 21.0 < 22.0\n",
      "2024-06-06 18:11:38,096 - Data_Validation.py - WARNING - Column SBP max value anomaly: 296.0 > 281.0\n",
      "2024-06-06 18:11:38,121 - Data_Validation.py - WARNING - Column DBP max value anomaly: 300.0 > 298.0\n",
      "2024-06-06 18:11:38,132 - Data_Validation.py - WARNING - Column Resp max value anomaly: 99.0 > 69.0\n",
      "2024-06-06 18:11:38,165 - Data_Validation.py - WARNING - Column FiO2 max value anomaly: 4000.0 > 10.0\n",
      "2024-06-06 18:11:38,204 - Data_Validation.py - WARNING - Column AST min value anomaly: 3.0 < 4.0\n",
      "2024-06-06 18:11:38,222 - Data_Validation.py - WARNING - Column BUN max value anomaly: 268.0 > 266.0\n",
      "2024-06-06 18:11:38,245 - Data_Validation.py - WARNING - Column Calcium min value anomaly: 1.0 < 1.6\n",
      "2024-06-06 18:11:38,250 - Data_Validation.py - WARNING - Column Calcium max value anomaly: 25.2 > 22.0\n",
      "2024-06-06 18:11:38,282 - Data_Validation.py - WARNING - Column Bilirubin_direct min value anomaly: 0.01 < 0.1\n",
      "2024-06-06 18:11:38,310 - Data_Validation.py - WARNING - Column Magnesium max value anomaly: 9.8 > 9.7\n",
      "2024-06-06 18:11:38,342 - Data_Validation.py - WARNING - Column Bilirubin_total max value anomaly: 49.2 > 46.6\n",
      "2024-06-06 18:11:38,351 - Data_Validation.py - WARNING - Column TroponinI min value anomaly: 0.01 < 0.3\n",
      "2024-06-06 18:11:38,356 - Data_Validation.py - WARNING - Column TroponinI max value anomaly: 381.6 > 49.3\n",
      "2024-06-06 18:11:38,384 - Data_Validation.py - WARNING - Column PTT max value anomaly: 249.9 > 150.0\n",
      "2024-06-06 18:11:38,411 - Data_Validation.py - WARNING - Column Platelets min value anomaly: 2.0 < 5.0\n",
      "2024-06-06 18:11:38,421 - Data_Validation.py - WARNING - Column Age min value anomaly: 16.0 < 18.11\n",
      "2024-06-06 18:11:38,422 - Data_Validation.py - WARNING - Column Age max value anomaly: 100.0 > 89.0\n",
      "2024-06-06 18:11:38,458 - Data_Validation.py - INFO - Statistical validation passed.\n",
      "2024-06-06 18:11:38,458 - Data_Validation.py - INFO - Data validation passed.\n"
     ]
    }
   ],
   "source": [
    "validation_result = validate_data(test_df)\n",
    "if not validation_result:\n",
    "    raise ValueError(\"Data validation failed. Stopping DAG execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>Patient_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.51</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699612</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.51</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699613</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.51</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699614</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>77.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "      <td>42.51</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699615</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.33</td>\n",
       "      <td>110.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.51</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927802</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>83.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>114990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927803</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>114990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927804</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>114990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927805</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>114990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927806</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>114990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228196 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Hour    HR  O2Sat   Temp    SBP   MAP   DBP  Resp  EtCO2  \\\n",
       "699611           0     0   NaN    NaN    NaN    NaN   NaN   NaN   NaN    NaN   \n",
       "699612           1     1  82.0  100.0    NaN  110.0  76.0   NaN  11.0    NaN   \n",
       "699613           2     2  81.0   97.0    NaN  110.0  77.0   NaN  14.0    NaN   \n",
       "699614           3     3  77.0  100.0    NaN  111.0  73.0   NaN  12.0    NaN   \n",
       "699615           4     4  76.0  100.0  37.33  110.0  74.0   NaN  11.0    NaN   \n",
       "...            ...   ...   ...    ...    ...    ...   ...   ...   ...    ...   \n",
       "927802          16    16  83.0   93.0    NaN  126.0  95.0  86.0  15.0    NaN   \n",
       "927803          17    17  78.0  100.0    NaN  118.0  88.0  82.0  16.0    NaN   \n",
       "927804          18    18  83.0  100.0    NaN  117.0  86.0  78.0  17.0    NaN   \n",
       "927805          19    19  79.0  100.0    NaN  120.0  91.0  87.0  18.0    NaN   \n",
       "927806          20    20  79.0  100.0    NaN  123.0  91.0  82.0  18.0    NaN   \n",
       "\n",
       "        ...  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "699611  ...         NaN        NaN  42.51       1    NaN    NaN        -0.01   \n",
       "699612  ...         NaN        NaN  42.51       1    NaN    NaN        -0.01   \n",
       "699613  ...         NaN        NaN  42.51       1    NaN    NaN        -0.01   \n",
       "699614  ...         NaN      238.0  42.51       1    NaN    NaN        -0.01   \n",
       "699615  ...         NaN        NaN  42.51       1    NaN    NaN        -0.01   \n",
       "...     ...         ...        ...    ...     ...    ...    ...          ...   \n",
       "927802  ...         NaN        NaN  33.00       1    1.0    0.0        -4.88   \n",
       "927803  ...         NaN        NaN  33.00       1    1.0    0.0        -4.88   \n",
       "927804  ...         NaN        NaN  33.00       1    1.0    0.0        -4.88   \n",
       "927805  ...         NaN        NaN  33.00       1    1.0    0.0        -4.88   \n",
       "927806  ...         NaN        NaN  33.00       1    1.0    0.0        -4.88   \n",
       "\n",
       "        ICULOS  SepsisLabel  Patient_ID  \n",
       "699611       1            0       11905  \n",
       "699612       2            0       11905  \n",
       "699613       3            0       11905  \n",
       "699614       4            0       11905  \n",
       "699615       5            0       11905  \n",
       "...        ...          ...         ...  \n",
       "927802      17            0      114990  \n",
       "927803      18            0      114990  \n",
       "927804      19            0      114990  \n",
       "927805      20            0      114990  \n",
       "927806      21            0      114990  \n",
       "\n",
       "[228196 rows x 44 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('machine-learning-tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31384ce3dd6bc2c85be3c3d887d32a02f47760f0703449b13d0f58d482b7108e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
